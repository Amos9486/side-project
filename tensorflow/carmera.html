<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Camera Input Detection</title>
    <!-- 引入tensorFlow.js  -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
  </head>
  <body>
    <video id="video" style="display: none"></video>
    <canvas id="cvs"></canvas>

    <script>
      // 建立初始化程序 1.載入Blazeface模型 2.準備視訊
      const video = document.querySelector("#video");
      const ctx = document.querySelector("#cvs").getContext("2d");

      //   載入Blazeface模型(一開始載入可以提升效能)
      // 因為要用await 故需要用async function 包起來
      let model = "";
      async function init() {
        model = await blazeface.load();
        // 確保video 已經開始撥放了
        video.addEventListener("loadeddata", () => {
          //   將模組引入video 播放
          window.setInterval(refresh, 10);
        });
        //   取得電腦視訊裝置

        window.navigator.mediaDevices
          .getUserMedia({
            audio: false,
            video: true,
          })
          .then((steam) => {
            video.srcObject = steam;
            // 啟動視訊
            video.play();
          });
      }
      init();

      async function refresh() {
        //   不需要每次重新載入模型，故將這部分移至一開始載入
        //   載入Blazeface模型
        // const model = await blazeface.load();

        // 利用圖形做圖片作臉部辨識
        // returnTensors 針對結果作更多機器學習才會是true
        const returnTensors = false;
        // 因為會換圖片，每次皆須偵測
        const predictions = await model.estimateFaces(
          // document.querySelector("img")圖片物件/影片物件/Canvas 物件
          video,
          returnTensors
        );
        // 設定影像尺寸
        ctx.canvas.width = video.videoWidth;
        ctx.canvas.height = video.videoHeight;
        // 取的辨識結果 >0確實有找到臉部存在
        if (predictions.length > 0) {
          // 利用迴圈把所臉部位置呈現出來
          for (let i = 0; i < predictions.length; i++) {
            //   將眼睛位置畫出來
            const rightEye = predictions[i].landmarks[0]; //landmarks[0] = 右邊眼睛
            const leftEye = predictions[i].landmarks[1]; //landmarks[1] = 左邊眼睛

            const start = predictions[i].topLeft; //左上角
            const end = predictions[i].bottomRight; //右下角
            const size = [end[0] - start[0], end[1] - start[1]]; //長、寬

            // 把ctx.fillRect畫到canvas 上的動作(將臉部方形畫出來)
            // 建立一個裁切區塊 Path2D為 canvas 影像處理一部分
            const faceArea = new Path2D();
            // 在canvas 上定義一個橢圓形區塊
            // (leftEye[0]+rightEye[0])/2,(leftEye[1]+rightEye[1])/2 橢圓圓心(x,y)
            // size[0]*0.5,size[0]*0.8 半徑
            // 0 為旋轉角度
            faceArea.ellipse(
              (leftEye[0] + rightEye[0]) / 2,
              (leftEye[1] + rightEye[1]) / 2,
              size[0] * 0.5,
              size[0] * 0.65,
              0,
              0,
              2 * Math.PI
            );
            // 在canvas 上定義一個方形區塊(.rect(座標))
            // faceArea.rect(start[0], start[1], size[0], size[1]);
            // 只把圖片畫在上面定義的路徑中
            ctx.save(); //canvas 儲存設定
            // 將方形區塊裁切出來
            ctx.clip(faceArea);
            // 將整張圖畫上canvas (因為先求有做clip ，所以實際只會畫到clip後的區塊中)
            ctx.filter = "blur(10px)";
            ctx.drawImage(video, 0, 0);

            // ctx.ctx.fillRect(start[0], start[1], size[0], size[1]); //(左上角x座標,左上角y座標,寬,高)
            ctx.restore(); //恢復canvas的設定
          }
        }
        // 補上模糊背景
        ctx.save();
        // 設定濾鏡
        // ctx.filter = "blur(10px)";
        // 當組合時,要做一些事情(合成效果)
        // destination-atop舊圖形只保留在新、舊圖形重疊的舊圖形區域，然後蓋在新圖形之上。
        ctx.globalCompositeOperation = "destination-atop";
        // 再將影像畫一次
        ctx.drawImage(video, 0, 0);
        ctx.restore();
      }
    </script>
  </body>
</html>
