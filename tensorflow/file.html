<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>File Input Detection</title>
    <!-- 引入tensorFlow.js  -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
  </head>
  <body>
    <!-- onchange 當使用者選擇改變 -->
    <div class="">選擇檔案<input type="file" onchange="loadFile(this)" /></div>

    <canvas id="cvs"></canvas>

    <script>
      // 宣告canves 取的這個畫布 getContext物件  對畫布做影像處理
      const ctx = document.querySelector("#cvs").getContext("2d");

      //   載入Blazeface模型(一開始載入可以提升效能)
      // 因為要用await 故需要用async function 包起來
      let model = "";
      async function init() {
        model = await blazeface.load();
      }
      init();

      function loadFile(input) {
        // 取得使用者選擇的檔案
        const file = input.files[0];
        console.log(file);

        // *******
        // 把檔案物件變成圖片物件
        const img = new Image();
        // 產生一個隨機的網址 對應到檔案物件
        img.src = URL.createObjectURL(file);
        console.log(img.src); //blob:http://127.0.0.1:5500/dac21f2e-721c-4e9f-9fa3-430e9ab37e45
        img.addEventListener("load", () => {
          // 將圖片長/寬指向給canvas
          ctx.canvas.width = img.width;
          ctx.canvas.height = img.height;
          // 畫出圖片(圖片,從左上角,到右下角)
          // ctx.drawImage(img, 0, 0);
          // 暫時不畫圖片
          // 將檔案傳入Blazeface模型
          detect(img);
        });
      }
      async function detect(img) {
        //   不需要每次重新載入模型，故將這部分移至一開始載入
        //   載入Blazeface模型
        // const model = await blazeface.load();

        // 利用圖形做圖片作臉部辨識
        // returnTensors 針對結果作更多機器學習才會是true
        const returnTensors = false;
        // 因為會換圖片，每次皆須偵測
        const predictions = await model.estimateFaces(
          // document.querySelector("img")圖片物件/影片物件/Canvas 物件
          img,
          returnTensors
        );
        // 取的辨識結果 >0確實有找到臉部存在
        if (predictions.length > 0) {
          // 利用迴圈把所臉部位置呈現出來
          for (let i = 0; i < predictions.length; i++) {
            //   將眼睛位置畫出來
            const rightEye = predictions[i].landmarks[0]; //landmarks[0] = 右邊眼睛
            const leftEye = predictions[i].landmarks[1]; //landmarks[1] = 左邊眼睛

            const start = predictions[i].topLeft; //左上角
            const end = predictions[i].bottomRight; //右下角
            const size = [end[0] - start[0], end[1] - start[1]]; //長、寬

            // 把ctx.fillRect畫到canvas 上的動作(將臉部方形畫出來)
            // 建立一個裁切區塊 Path2D為 canvas 影像處理一部分
            const faceArea = new Path2D();
            // 在canvas 上定義一個橢圓形區塊
            // (leftEye[0]+rightEye[0])/2,(leftEye[1]+rightEye[1])/2 橢圓圓心(x,y)
            // size[0]*0.5,size[0]*0.8 半徑
            // 0 為旋轉角度
            faceArea.ellipse(
              (leftEye[0] + rightEye[0]) / 2,
              (leftEye[1] + rightEye[1]) / 2,
              size[0] * 0.5,
              size[0] * 0.65,
              0,
              0,
              2 * Math.PI
            );
            // 在canvas 上定義一個方形區塊(.rect(座標))
            // faceArea.rect(start[0], start[1], size[0], size[1]);
            // 只把圖片畫在上面定義的路徑中
            ctx.save(); //canvas 儲存設定
            // 將方形區塊裁切出來
            ctx.clip(faceArea);
            // 將整張圖畫上canvas (因為先求有做clip ，所以實際只會畫到clip後的區塊中)
            ctx.drawImage(img, 0, 0);

            // ctx.ctx.fillRect(start[0], start[1], size[0], size[1]); //(左上角x座標,左上角y座標,寬,高)
            ctx.restore(); //恢復canvas的設定
          }
        }
        // 補上模糊背景
        ctx.save();
        // 設定濾鏡
        ctx.filter = "blur(10px)";
        // 當組合時,要做一些事情(合成效果)
        // destination-atop舊圖形只保留在新、舊圖形重疊的舊圖形區域，然後蓋在新圖形之上。
        ctx.globalCompositeOperation = "destination-atop";
        // 再將影像畫一次
        ctx.drawImage(img, 0, 0);
        ctx.restore();
      }

      /*
    `predictions` is an array of objects describing each detected face, for example:

    [
      {
        //   一張臉的左上角
        topLeft: [232.28, 145.26],
        //  一張臉的右下角
        bottomRight: [449.75, 308.36],
        // 成功機率
        probability: [0.998],
        // 每一個關鍵地方位置
        landmarks: [
          [295.13, 177.64], // right eye
          [382.32, 175.56], // left eye
          [341.18, 205.03], // nose
          [345.12, 250.61], // mouth
          [252.76, 211.37], // right ear
          [431.20, 204.93] // left ear
        ]
      }
    ]
    */

      //   main();
    </script>
  </body>
</html>
